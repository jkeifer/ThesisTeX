\chapter{Data and Methods}
\label{chapter:methods}

\section{Overview}

This study has two purposes: (1) develop a set of tools to allow the classification of agricultural crops using a time series of imagery and known crop reference signatures, and (2) test the portability of the reference signatures. The known crop reference signatures were extracted from the Kansas study site, and their portability was tested by using them to classify the Argentina study site. The data used for this study consist of the following:

\begin{Spacing}{1.2}
\begin{itemize}
  \item 250-meter MODIS 16-day Composite Vegetation Index images
  \item 30-meter 2012 USDA Cropland Data Layer (CDL): agricultural land cover raster dataset
  \item 30-meter Landsat 8 Operational Land Imager satellite imagery
  \item Shapefile of the administrative boundary of the Department of Pellegrini
  \item 2014 Land cover vector dataset with crop identifications for Pellegrini
\end{itemize}
\end{Spacing}

The first three datasets are publicly available from U.S. agencies. The Pellegrini boundary is from the GDAM Global Administrative Areas Dataset, version 1.0 (available at http://www.gdam.org). The land cover dataset for Pellegrini was digitized from Landsat 8 images (path 230, row 78), and the crop identifications were collected in the field.

An outline of the processing workflow is below:

\begin{Spacing}{1.2}
\begin{enumerate}
  \item Reproject the MODIS composite imagery
  \item Assemble individual composite images into single time series images, one for Kansas and one for Argentina
  \item Identify all the ``pure'' pixels---those containing a single land cover type (e.g. non-mixels)---in the Kansas TSI by overlaying the CDL with the MODIS pixel grid
  \item Use the CDL to isolate the pure corn, soy, and sorghum pixels in the Kansas TSI
  \item Identify the unique phenological groups in each set of isolated pixels using k-means clustering
  \item Extract the pixel values for each unique phenological group from the time series image and find the mean value for each date to form the unique signatures for each crop
  \item Fit the Kansas signatures to the Kansas TSI using the TSF method (see \autoref{chapter:methods:phenology-fitting})
  \item Classify the Kansas RMSE rasters and assess the classification accuracy
  \item Fit the Kansas signatures to the Argentina TSI
  \item Classify the Argentina RMSE rasters and assess the accuracy
\end{enumerate}
\end{Spacing}

This chapter is a look at the methods and fieldwork used to create the validation land cover dataset of Pellegrini, and the data processing steps used to generate the study results. Details about the specific tools in the classification toolset and the development process can be found in Appendix \ref{appendix:tools}. For a detailed explanation of all the testing proceeding this study, please see Appendix \ref{appendix:testing}. A thorough recounting of my field experience can be found in Appendix \ref{appendix:fieldwork}.


\section{Field Methods and Data Collection in Pellegrini}

While ground truth data was easily available for the Kansas study site, getting a ground truth dataset for verification of the classification in Pellegrini was not so simple. Such a dataset did not exist, necessitating onsite data collection. I visited Argentina mid-March to early April 2014 to gather field observations of summer crop types and to talk to local farmers about typical agricultural practices, summer and winter crop varieties, and planting and harvesting dates.

To guide my ground truth collection, I generated 400 random points inside the Pellegrini shapefile boundary, and used a Landsat OLI image as a reference for land cover (image date \formatdate{5}{2}{2014}). Where a point fell within a mixel, I allowed it to be moved within a 3-by-3 pixel window centered on the point's original pixel, trying as much as possible to keep the point within a pixel belonging to the feature type on which it originally fell. In certain limited cases, if a point fell quite obviously within a field but the center pixel and eight surrounding pixels were mixels and/or were not within the field, I allowed the point to be moved to the closest full pixel of that same continuous field. Of the 400 points, I had to move 106 within the 3-by-3 window, and ten to a non-neighboring pixel within the same field.

From these adjusted points, I was able to establish 247 were forested using Landsat imagery. I did not need to visit these. For each of the remaining 153 I did need to visit, I created map sheets---one for every point, centered on the point---showing the point and satellite imagery at three different scales: (1) an overview at 1:60,000 scale with a Landsat OLI image; (2) a closer view at 1:30,000 scale, again with a Landsat OLI image, with an addition overlay of the MODIS pixel grid; and (3) a very large scale 1:4,500 scale view with older but higher resolution imagery from Digital Globe. I also created a 25-kilometer grid over Pellegrini, which I used to make eighteen smaller-scale ``regional'' maps at 1:150,000 scale to help identify neighboring points and plan routes. Lastly, I made an overview map of the entire department at 1:475,000 scale. I printed all of these maps and put them in a binder, so I could take notes and record the crop types in the field. I also planned to collect data about as many fields as I could, even those without sample points.
 
The primary means of gathering the crop identities to complete the ground truth was direct observation. When direct observation was not possible, I interviewed local farmers and land owners. In such cases, the interviewees were asked to identify their fields on the printed maps and describe their cultivars. Finally, if no knowledgable local could be found, visual interpretation of the Landsat imagery was attempted using the appearance of already-identified fields as reference. If an identification held uncertainty, the point was removed from the sample set. All the collected data was recorded directly on the sample point maps and later manually digitized.

Ancillary information about agricultural practices in the region was also collected whenever possible. It was a key goal to identify each crop's date range for planting and harvesting in order to allow the proper selection of MODIS imagery dates and setting of the $tshift$ bounds for \autoref{eq:gofx}.

\section{Data Processing}

\subsection{Resampling the CDL}

To use the CDL as a ground truth with the Kansas TSI, the 30-meter CDL pixels were resampled by majority to match the larger TSI pixels. This allowed a direct comparison between the crop values from the CDL and the pixel signatures in the TSI.

\subsection{Building the TSIs}

For this study, I chose to classify the 2012 Kansas summer growing season and the 2014 Argentina summer growing season. I assembled the MODIS 16-day composite VI images into multi-date time-series images (TSI) covering the growth cycle of the summer crops, where each band in a TSI is a 16-day composite VI and the bands are ordered consecutively (see Appendix \ref{appendix:tools:build} for the description of the Build Multidate Image Tools). The Kansas summer TSI covered the date range DOY 97 through DOY 273, and was made with data from the Terra satellite (LPDAAC product MOD13Q1, tile h10v05). Prior to creating the TSIs, each of the 16-day composites was reprojected from the native MODIS sinusoidal reference system using LPDAAC's MODIS Reprojection Tool \autocite{modis4.1}. I reprojected the Kansas data into the Albers Equal Area Conic projection for the contiguous USA using the 1983 North American Datum (WKID: 5070) to match the reference system of the USDA CDL.

In Argentina, as it is in the Southern Hemisphere and the seasons are inverted to those of the Northern hemisphere, the growing season shifts, as must the date range for the VI time-series. The TSI for Pellegrini must begin at the end of the proceeding year to adequately capture the entirety of the summer phenologies. To accomplish this, the time-series image for summer 2014 began with the 16-day composite image from DOY 353 of 2013 (or DOY âˆ’13 with reference to 2014) and ended with the image from DOY 161 of 2014 (MODIS grid tile h12v11). This specific date range was chosen based on information provided by local farmers to ensure coverage of the earliest planting and latest harvesting dates, as well as manual inspection of pixel signatures throughout the study area. Persistent clouds necessitated using an image from the Aqua satellite of DOY 105 (LPDAAC product MYD13Q1) in place of DOY 113 from Terra. Due to no viable imagery from Aqua or Terra, DOY 129 was interpolated via a simple mean from the DOY 105 Aqua image and the DOY 145 Terra image. The Argentina composite images were reprojected with the UTM Zone 20S reference system (WKID: 32720).

\subsection{Eliminating Mixels}

After building the TSIs, the next processing step was to eliminate mixels from the TSIs, to prevent errors caused by mixed temporal signatures (see Appendix \ref{appendix:testing:r2} for more information). Pure pixels, the non-mixels in an image, were isolated by intersecting the ground truth datasets with a vector grid of the TSI pixels. Then, all pixels with an area greater than an area threshold were selected as pure. Only these pure pixels were classified; the mixels in the TSIs were excluded.

The original 30-meter CDL raster served as the reference for finding the pure pixels in the Kansas study site. The raster was converted to vector polygons and intersected with the TSI grid polygons. From the resulting geometry, all polygons greater than 53,000 square meters (or 98 percent of a full MODIS pixel) were selected as pure. I also manually selected two sorghum pixel features that were omitted due to intermixed soy pixels. I chose to add these pixels due to the low number of sorghum features retained, and that the intermixed soy appeared to be errors.

For the Argentina analysis, the digitized features of identified fields were combined with manually digitized features of all large forested areas, unknown fields, and ``other'' areas. Some places where the land cover was mixed and could not be visually differentiated were not digitized and were considered to be composed entirely of mixels. The complete dataset of land cover was then intersected with the Argentina TSI grid. Through trial and error, a minimum area of 50,000 square meters was chosen as the threshold for pure pixels in the image.

\subsection{Extracting the Reference Temporal Signatures}

As a reference library of temporal signatures does not yet exist, I had to extract my own signatures from the Kansas TSI. To do so, the pure TSI pixels of each key summer crop---corn, soy, and sorghum---as specified in the resampled CDL were isolated in separate rasters. Each of separated rasters was clustered into three clusters using the ENVI \autocite{envi5.0} k-means tool with a 1.0 percent change threshold over 100 maximum iterations. The TSI pixels in each cluster were then sampled and averaged to find the three primary signatures for each crop\footnote{Given the existing literature about phenological classification, I do not believe crops have multiple signatures. I believe every crop as a theoretical ideal signature, which can be made to fit any actual signature using the $xscale$, $yscale$, and $tshift$ transformations in Equation \ref{eq:gofx}, barring any unusual effects of weather or other forces impacting crop development (a mid-season drought, for example, may cause a crop signature with double peaks due to the partial dying off and regeneration of the plants). However, given my choice of the CDL as my source of ground truth, I have had to make the assumption that it is highly accurate, despite any evidence to the contrary (see my discussion of the CDL beginning in \autoref{appendix:testing:r3}). Therefore, I use the clustering to derive the signatures that will create a classification most comparable to the CDL.} (see \autoref{appendix:tools:extract} for information about the Extract Signatures Tool).

\subsection{Fitting the Reference Signatures to the TSIs}

\autoref{eq:1} (page \pageref{eq:1}) was implemented using the programming language Python \autocite{python2.7.8} with a command line interface to allow easy processing of the TSIs. Details of the tool can be found in \autoref{appendix:tools:fit} on page \pageref{appendix:tools:fit}. The tool iterates through every pixel in a TSI, comparing each reference signature with the pixel signature. The tool is able clip an input TSI to either pixel bounds or a shapefile containing a polygon, and can also use an optional point shapefile to limit the processed pixels to only those coincident with points. An output raster is created for each signature to record the RMSE from every pixel comparison.

The reference signatures extracted from the Kansas TSI clusters were fit to the Kansas TSI to verify the classifier. The TSI was clipped to pixel row 2482 and column 1089, extending 100 rows and 100 columns. Then, the same Kansas signatures were fit to the Pellegrini TSI, which was clipped to the boundary shapefile. The fit rasters from each TSI were then classified. In both cases, the bounds for the $xscale$ and $yscale$ parameters were 0.6 to 1.4. The $tshift$ bounds for the Kansas processing were -10 to +10 days, while the bounds for the Pellegrini processing were 120 to 140 days (still $\pm10$ days, but shifted 130 days).\footnote{I have not formally tested other bounds. See Appendix \ref{appendix:future:fitting}.}

\subsection{Classifying the Fit Rasters}

The classification process is complex; Appendix \ref{appendix:tools:classify} contains a full discussion of the process, so I will refrain from a lengthy description here.

Classifying the fit rasters first requires thresholding the values in each raster, then finding the lowest value for each pixel. The signature with the lowest thresholded fit value has the best fit, and the pixel is classified as that crop. The thresholding prevents pixels with poor fit values from being classified as a crop. If a pixel has no remaining fit values after thresholding, it is classified as ``other.'' Currently, appropriate threshold values are not well understood, so to find the best classification, the classification tool must brute-force through many combinations of thresholds within a user-specified range, classifying the fit rasters, and calculating the accuracy of each threshold combination in comparison with the ground truth dataset. A raster of the classification with the best accuracy is retained.

For the Kansas classification, it was easy to try iterating through different threshold ranges. However, the Argentina classification was not as straightforward. As the tool must brute-force through every threshold combination, the time required to find the best threshold in a range is exponential, given by the number of threshold steps to the power of the number of images, times the number of seconds for each iteration. The Kansas classification took under 0.3 seconds per iteration; classifying the larger area of Pellegrini took substantially more time, somewhere between three and four seconds per iteration. The increased processing time ruled out using more than two or three steps in any given iteration. Consequently, in the case of the Argentina classification, I found it much more efficient to iterate through a range of threshold values using a single threshold value across all the fit rasters, then manually refine the thresholds until a suitable threshold combination was found.